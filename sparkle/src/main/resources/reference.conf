sparkle-time-server {
  // start the protocol server at launch
  auto-start = true

  // custom HTTP APIs 
  apis = []
  
  // driver to use for reading (storage is typically e.g. cassandra or RAM.  Or build your own that fulfills the Storage api)
  store = nest.sparkle.store.cassandra.ConfiguredCassandra
  
  // driver to use for writing to storage (e.g. for stream loading)
  writeable-store = nest.sparkle.store.cassandra.ConfiguredCassandra
  
  // erase and reformat the store on launch (e.g. for integration tests)
  erase-store = false
  
  // set to [*] to open /v1/data api to _all_ requests (useful for internal development) 
  cors-hosts = []
  
  files-loader {
    auto-start = false
    
    // set to paths of file system directories containing data files to load into the server
    // the directories are recursively searched for .csv/.tsv files
    directories = []
  }
  
  // configuration for the cassandra storage
  sparkle-store-cassandra {
    contact-hosts = [localhost] 
    key-space = events
  }
  
  // tcp port for http connections
  port = 1234
  
  // directory containing web dashboard content to serve 
  web-root = "."
  
  logback {   
    // file into which to write log messages
    file = sparkle.log
    
    // logback log pattern
    pattern = "%date{MM/dd HH:mm:ss.SSS} %-5level %logger{1} - %msg%n"
    
    // append, or start a new log file with each execution
    append = false    
  }
  
  akka {
    loglevel = DEBUG
    loggers = ["akka.event.slf4j.Slf4jLogger"]
    log-dead-letters = 0
    log-dead-letters-during-shutdown = off   // to quiet IO-HTTP/listener
  }
}

exporter {
  timeout = 5m  // time to wait for an export to complete
}


