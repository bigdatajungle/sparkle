kafka-loader {
  kafka-reader {   // these are copied verbatim to the kafka consumer see http://kafka.apache.org/08/configuration.html
    zookeeper.connect = "localhost:2181"    
    zookeeper.session.timeout.ms = 4000
    zookeeper.sync.time.ms = 200
    auto.offset.reset = smallest
    auto.commit.interval.ms = 1000
    auto.commit.enable = false
    consumer.timeout.ms = 10000
  }
  reader {
    consumer-group = "defaultConsumer"
  }
  
  kafka-writer {   // these are copied verbatim to the kafka producer see http://kafka.apache.org/08/configuration.html 
    metadata.broker.list = "localhost:9092"
    request.required.acks = 1
  }
  
  // list of topics to stream load
  topics = []
  
  // class to identify the avro schema for each topic 
  // (the class must have a zero argument constructor and implement the trait AvroExtract)
  find-decoder = ""
  
  log4j {
    // path and log file name 
    file = "kafka-client.log"    
    
    // whether to start a new log file with each execution 
    append = false    
    
    // log4j log pattern
    pattern = "%d{MM/dd HH:mm:ss.SSS} %-5p %c{1} - %m%n"    
  }
  
}
