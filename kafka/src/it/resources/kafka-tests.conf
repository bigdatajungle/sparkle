sparkle-time-server { // TODO rename to sparkle
  
  logging {
    provider = log4j
    
    levels {
      root = DEBUG
      kafka.network = WARN
      kafka.utils = WARN
      kafka.client = WARN 
      kafka.consumer = ERROR
      kafka.producer.SyncProducer = WARN
      kafka.producer.BrokerPartitionInfo = ERROR
      kafka.producer.async.DefaultEventHandler = FATAL
      com.datastax = WARN
      nest.sparkle = DEBUG      
//      nest.sparkle.loader.kafka.KafkaAvroArrayTopicLoader = TRACE      
    }
    
    file {
      path = "/tmp/sparkle-kafka-tests.log"
    }
        
  }
  
  kafka-loader {
    commit-interval = 100ms
    reader {
      // the kafka reader uses a consumer group per topic to avoid issues restarting the
      consumer-group-prefix = "itConsumer"
      consumer-group-prefix = ${?SPARKLE_CONSUMER_GROUP_PREFIX}
    }
  }
  

}
